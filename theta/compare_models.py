#!/usr/bin/env python3
"""
æ¨¡å‹å¯¹æ¯”åˆ†æè„šæœ¬ - å¯¹æ¯”ä¸åŒSDVæ¨¡å‹çš„ç”Ÿæˆç»“æœ
"""

import pandas as pd
import numpy as np
import os
import glob
from datetime import datetime

def load_synthetic_data():
    """åŠ è½½æ‰€æœ‰æ¨¡å‹çš„åˆæˆæ•°æ®"""
    models_data = {}
    
    output_dir = "output"
    if not os.path.exists(output_dir):
        print("âŒ è¾“å‡ºç›®å½•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œæ¨¡å‹ç”Ÿæˆæ•°æ®")
        return {}
    
    for model_name in ['gaussian_copula', 'ctgan', 'copulagan', 'tvae', 'par']:
        model_dir = os.path.join(output_dir, model_name)
        if os.path.exists(model_dir):
            # æŸ¥æ‰¾åˆæˆæ•°æ®æ–‡ä»¶
            data_files = glob.glob(os.path.join(model_dir, "*_synthetic_data.csv"))
            if data_files:
                try:
                    df = pd.read_csv(data_files[0])
                    models_data[model_name] = df
                    print(f"âœ… åŠ è½½ {model_name} æ•°æ®: {df.shape}")
                except Exception as e:
                    print(f"âŒ åŠ è½½ {model_name} æ•°æ®å¤±è´¥: {e}")
            else:
                print(f"âš ï¸  æœªæ‰¾åˆ° {model_name} çš„åˆæˆæ•°æ®æ–‡ä»¶")
    
    return models_data

def load_quality_scores():
    """åŠ è½½æ‰€æœ‰æ¨¡å‹çš„è´¨é‡åˆ†æ•°"""
    quality_scores = {}
    
    output_dir = "output"
    for model_name in ['gaussian_copula', 'ctgan', 'copulagan', 'tvae', 'par']:
        model_dir = os.path.join(output_dir, model_name)
        if os.path.exists(model_dir):
            summary_files = glob.glob(os.path.join(model_dir, "*_summary.txt"))
            if summary_files:
                try:
                    with open(summary_files[0], 'r', encoding='utf-8') as f:
                        content = f.read()
                        # æå–è´¨é‡åˆ†æ•°
                        for line in content.split('\n'):
                            if 'è´¨é‡åˆ†æ•°:' in line and '%' in line:
                                score_str = line.split('è´¨é‡åˆ†æ•°:')[1].strip()
                                if score_str != 'æ— æ³•è·å–':
                                    score = float(score_str.replace('%', ''))
                                    quality_scores[model_name] = score
                                    break
                except Exception as e:
                    print(f"âŒ è¯»å– {model_name} è´¨é‡åˆ†æ•°å¤±è´¥: {e}")
    
    return quality_scores

def compare_data_distributions(models_data):
    """å¯¹æ¯”æ•°æ®åˆ†å¸ƒ"""
    print("\nğŸ“Š æ•°æ®åˆ†å¸ƒå¯¹æ¯”åˆ†æ")
    print("="*60)
    
    if not models_data:
        print("âŒ æ²¡æœ‰å¯ç”¨çš„æ¨¡å‹æ•°æ®è¿›è¡Œå¯¹æ¯”")
        return
    
    # è·å–æ•°å€¼åˆ—
    first_model = list(models_data.keys())[0]
    numeric_columns = models_data[first_model].select_dtypes(include=[np.number]).columns
    
    comparison_results = {}
    
    for col in numeric_columns[:5]:  # åªå¯¹æ¯”å‰5ä¸ªæ•°å€¼åˆ—
        print(f"\nåˆ—: {col}")
        print("-" * 40)
        
        col_comparison = {}
        for model_name, data in models_data.items():
            if col in data.columns:
                stats = data[col].describe()
                col_comparison[model_name] = {
                    'mean': stats['mean'],
                    'std': stats['std'],
                    'min': stats['min'],
                    'max': stats['max'],
                    'median': stats['50%']
                }
                print(f"{model_name:15} | å‡å€¼: {stats['mean']:.2f} | æ ‡å‡†å·®: {stats['std']:.2f}")
        
        comparison_results[col] = col_comparison
    
    return comparison_results

def analyze_sequential_patterns(models_data):
    """åˆ†æåºåˆ—æ¨¡å¼ï¼ˆç‰¹åˆ«é’ˆå¯¹PARæ¨¡å‹ï¼‰"""
    print("\nğŸ”„ åºåˆ—æ¨¡å¼åˆ†æ")
    print("="*60)
    
    for model_name, data in models_data.items():
        if 'user_id' in data.columns:
            user_counts = data['user_id'].value_counts()
            print(f"\n{model_name} åºåˆ—ç‰¹å¾:")
            print(f"  - ç”¨æˆ·æ•°é‡: {data['user_id'].nunique()}")
            print(f"  - æ€»è®°å½•æ•°: {len(data)}")
            print(f"  - å¹³å‡åºåˆ—é•¿åº¦: {user_counts.mean():.1f}")
            print(f"  - åºåˆ—é•¿åº¦èŒƒå›´: {user_counts.min()} - {user_counts.max()}")

def create_comparison_report(models_data, quality_scores):
    """åˆ›å»ºå¯¹æ¯”æŠ¥å‘Š"""
    print("\nğŸ“‹ ç”Ÿæˆç»¼åˆå¯¹æ¯”æŠ¥å‘Š")
    
    report_content = []
    report_content.append("=" * 80)
    report_content.append("SDV æ¨¡å‹å¯¹æ¯”åˆ†ææŠ¥å‘Š")
    report_content.append("=" * 80)
    report_content.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now()}")
    report_content.append("")
    
    # 1. åŸºæœ¬ä¿¡æ¯å¯¹æ¯”
    report_content.append("1. åŸºæœ¬ä¿¡æ¯å¯¹æ¯”")
    report_content.append("-" * 40)
    report_content.append(f"{'æ¨¡å‹åç§°':<15} | {'æ•°æ®è¡Œæ•°':<10} | {'æ•°æ®åˆ—æ•°':<10} | {'è´¨é‡åˆ†æ•°':<10}")
    report_content.append("-" * 60)
    
    for model_name, data in models_data.items():
        quality_score = quality_scores.get(model_name, 'N/A')
        score_str = f"{quality_score:.2f}%" if isinstance(quality_score, (int, float)) else str(quality_score)
        report_content.append(f"{model_name:<15} | {len(data):<10} | {len(data.columns):<10} | {score_str:<10}")
    
    report_content.append("")
    
    # 2. è´¨é‡åˆ†æ•°æ’å
    if quality_scores:
        report_content.append("2. è´¨é‡åˆ†æ•°æ’å")
        report_content.append("-" * 40)
        
        sorted_scores = sorted(quality_scores.items(), key=lambda x: x[1], reverse=True)
        for i, (model_name, score) in enumerate(sorted_scores, 1):
            report_content.append(f"{i}. {model_name}: {score:.2f}%")
        
        report_content.append("")
    
    # 3. åºåˆ—æ¨¡å¼åˆ†æï¼ˆå¦‚æœæœ‰PARæ¨¡å‹ï¼‰
    if 'par' in models_data:
        report_content.append("3. åºåˆ—æ¨¡å¼åˆ†æ")
        report_content.append("-" * 40)
        
        for model_name, data in models_data.items():
            if 'user_id' in data.columns:
                user_counts = data['user_id'].value_counts()
                report_content.append(f"â€¢ {model_name}:")
                report_content.append(f"  - ç”¨æˆ·æ•°: {data['user_id'].nunique()}, æ€»è®°å½•: {len(data)}")
                report_content.append(f"  - å¹³å‡åºåˆ—é•¿åº¦: {user_counts.mean():.1f}")
        
        report_content.append("")
    
    # 4. æ¨¡å‹ç‰¹ç‚¹åˆ†æ
    report_content.append("4. æ¨¡å‹ç‰¹ç‚¹åˆ†æ")
    report_content.append("-" * 40)
    
    model_descriptions = {
        'gaussian_copula': 'ç»å…¸ç»Ÿè®¡æ¨¡å‹ï¼Œè®­ç»ƒå¿«é€Ÿï¼Œé€‚åˆç»“æ„åŒ–æ•°æ®',
        'ctgan': 'æ·±åº¦å­¦ä¹ GANæ¨¡å‹ï¼Œç”Ÿæˆè´¨é‡é«˜ï¼Œè®­ç»ƒæ—¶é—´è¾ƒé•¿',
        'copulagan': 'æ··åˆæ¨¡å‹ï¼Œå¹³è¡¡é€Ÿåº¦å’Œè´¨é‡',
        'tvae': 'å˜åˆ†è‡ªç¼–ç å™¨ï¼Œé€‚åˆç‰¹å¾å­¦ä¹ å’Œé™ç»´',
        'par': 'æ¦‚ç‡è‡ªå›å½’æ¨¡å‹ï¼Œä¸“é—¨ç”¨äºåºåˆ—/æ—¶é—´åºåˆ—æ•°æ®'
    }
    
    for model_name in models_data.keys():
        description = model_descriptions.get(model_name, 'æœªçŸ¥æ¨¡å‹')
        report_content.append(f"â€¢ {model_name}: {description}")
    
    report_content.append("")
    
    # 5. æ¨èå»ºè®®
    report_content.append("5. ä½¿ç”¨å»ºè®®")
    report_content.append("-" * 40)
    
    if quality_scores:
        best_model = max(quality_scores.items(), key=lambda x: x[1])
        report_content.append(f"â€¢ è´¨é‡æœ€ä½³: {best_model[0]} (åˆ†æ•°: {best_model[1]:.2f}%)")
    
    report_content.append("â€¢ é€Ÿåº¦ä¼˜å…ˆ: gaussian_copula")
    report_content.append("â€¢ è´¨é‡ä¼˜å…ˆ: ctgan")
    report_content.append("â€¢ å¹³è¡¡é€‰æ‹©: copulagan")
    report_content.append("â€¢ ç‰¹å¾å­¦ä¹ : tvae")
    report_content.append("â€¢ åºåˆ—/æ—¶é—´åºåˆ—: par")
    
    # ä¿å­˜æŠ¥å‘Š
    report_file = "output/models_comparison_report.txt"
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write('\n'.join(report_content))
    
    print(f"âœ… å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    # æ‰“å°åˆ°æ§åˆ¶å°
    print("\n" + "\n".join(report_content))

def main():
    print("ğŸ” å¼€å§‹æ¨¡å‹å¯¹æ¯”åˆ†æ")
    
    # 1. åŠ è½½æ•°æ®
    models_data = load_synthetic_data()
    if not models_data:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•æ¨¡å‹æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œ run_all_models.py")
        return
    
    # 2. åŠ è½½è´¨é‡åˆ†æ•°
    quality_scores = load_quality_scores()
    
    # 3. å¯¹æ¯”æ•°æ®åˆ†å¸ƒ
    compare_data_distributions(models_data)
    
    # 4. åˆ†æåºåˆ—æ¨¡å¼
    analyze_sequential_patterns(models_data)
    
    # 5. åˆ›å»ºç»¼åˆæŠ¥å‘Š
    create_comparison_report(models_data, quality_scores)
    
    print(f"\nğŸ‰ æ¨¡å‹å¯¹æ¯”åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main() 