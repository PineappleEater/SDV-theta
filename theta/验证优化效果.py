#!/usr/bin/env python3
"""
ğŸ¯ æ¨¡å‹ä¼˜åŒ–æ•ˆæœéªŒè¯è„šæœ¬
ç”¨äºå¯¹æ¯”ä¼˜åŒ–å‰åçš„æ¨¡å‹æ€§èƒ½ï¼ŒéªŒè¯å‚æ•°è°ƒä¼˜æ•ˆæœ
"""

import pandas as pd
import time
import os

def analyze_optimization_results():
    """åˆ†æä¼˜åŒ–æ•ˆæœ"""
    print("ğŸ¯ SDV-Theta æ¨¡å‹ä¼˜åŒ–æ•ˆæœéªŒè¯")
    print("=" * 60)
    
    # 1. æ£€æŸ¥æ˜¯å¦æœ‰æ–°çš„è®­ç»ƒç»“æœ
    models = ['gaussian_copula', 'ctgan', 'copulagan', 'tvae', 'par']
    
    print("ğŸ“Š æ£€æŸ¥æ¨¡å‹è®­ç»ƒç»“æœ...")
    results = {}
    
    for model in models:
        output_dir = f"output/{model}"
        if os.path.exists(output_dir):
            files = os.listdir(output_dir)
            csv_files = [f for f in files if f.endswith('.csv')]
            
            if csv_files:
                # è·å–æœ€æ–°çš„CSVæ–‡ä»¶
                latest_csv = max([os.path.join(output_dir, f) for f in csv_files], 
                                key=os.path.getmtime)
                modification_time = os.path.getmtime(latest_csv)
                
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æ˜¯æœ€è¿‘ç”Ÿæˆçš„ï¼ˆ1å°æ—¶å†…ï¼‰
                if time.time() - modification_time < 3600:
                    status = "âœ… æ–°ç”Ÿæˆ"
                    try:
                        df = pd.read_csv(latest_csv)
                        record_count = len(df)
                        indicator_count = df['indicator'].nunique() if 'indicator' in df.columns else 0
                    except:
                        record_count = 0
                        indicator_count = 0
                else:
                    status = "ğŸ• æ—§æ–‡ä»¶"
                    record_count = 0
                    indicator_count = 0
            else:
                status = "âŒ æ— ç»“æœ"
                record_count = 0
                indicator_count = 0
        else:
            status = "âŒ ç›®å½•ä¸å­˜åœ¨"
            record_count = 0
            indicator_count = 0
            
        results[model] = {
            'status': status,
            'records': record_count,
            'indicators': indicator_count
        }
        
        print(f"  {model.upper():15s}: {status:10s} ({record_count} æ¡è®°å½•, {indicator_count} æŒ‡æ ‡)")
    
    print()
    
    # 2. å¦‚æœæœ‰æ–°ç»“æœï¼Œè¿›è¡Œå¿«é€Ÿåˆ†æ
    new_results = [model for model, data in results.items() 
                   if data['status'] == "âœ… æ–°ç”Ÿæˆ" and data['records'] > 0]
    
    if new_results:
        print("ğŸ‰ å‘ç°æ–°çš„è®­ç»ƒç»“æœï¼")
        print(f"âœ… æˆåŠŸè®­ç»ƒçš„æ¨¡å‹: {', '.join([m.upper() for m in new_results])}")
        
        # 3. å¯¹æ¯”åˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰
        print("\nğŸ“ˆ å¿«é€Ÿæ€§èƒ½åˆ†æ...")
        
        # åŠ è½½åŸå§‹æ•°æ®ä½œä¸ºåŸºå‡†
        try:
            df_orig = pd.read_csv('source_data/th_series_data.csv', low_memory=False)
            user_169 = df_orig[df_orig['user_id'] == 169].sample(n=min(5000, len(df_orig[df_orig['user_id'] == 169])), random_state=42)
            orig_indicators = user_169['indicator'].value_counts().head(5)
            orig_total = len(user_169)
            
            print(f"ğŸ“Š åŸå§‹åŸºå‡†æ•°æ® (å‰5æŒ‡æ ‡):")
            for i, (ind, count) in enumerate(orig_indicators.items(), 1):
                freq = count / orig_total * 100
                print(f"  {i}. {ind[:30]:30s}: {freq:5.1f}%")
            
            print("\nğŸ” æ¨¡å‹è¡¨ç°å¯¹æ¯”:")
            
            for model in new_results:
                try:
                    output_dir = f"output/{model}"
                    csv_files = [f for f in os.listdir(output_dir) if f.endswith('.csv')]
                    if csv_files:
                        latest_csv = max([os.path.join(output_dir, f) for f in csv_files], 
                                        key=os.path.getmtime)
                        df_synt = pd.read_csv(latest_csv)
                        synt_indicators = df_synt['indicator'].value_counts()
                        synt_total = len(df_synt)
                        
                        print(f"\n--- {model.upper()} ---")
                        
                        # è®¡ç®—å‰5æŒ‡æ ‡çš„é¢‘ç‡è¯¯å·®
                        errors = []
                        for indicator in orig_indicators.head(5).index:
                            orig_freq = orig_indicators[indicator] / orig_total * 100
                            synt_count = synt_indicators.get(indicator, 0)
                            synt_freq = synt_count / synt_total * 100 if synt_total > 0 else 0
                            error = abs(orig_freq - synt_freq)
                            errors.append(error)
                            print(f"  {indicator[:25]:25s}: {synt_freq:5.1f}% (ç›®æ ‡: {orig_freq:5.1f}%, è¯¯å·®: {error:5.2f}%)")
                        
                        avg_error = sum(errors) / len(errors)
                        print(f"  ğŸ“Š å¹³å‡é¢‘ç‡è¯¯å·®: {avg_error:.2f}%")
                        
                        # åˆ¤æ–­ä¼˜åŒ–æ•ˆæœ
                        if avg_error < 0.5:
                            print(f"  ğŸ‰ ä¼˜ç§€è¡¨ç°ï¼")
                        elif avg_error < 1.0:
                            print(f"  âœ… è‰¯å¥½è¡¨ç°")
                        elif avg_error < 1.5:
                            print(f"  âš ï¸  éœ€è¦æ”¹è¿›")
                        else:
                            print(f"  âŒ è¡¨ç°ä¸ä½³")
                            
                except Exception as e:
                    print(f"  âŒ {model} åˆ†æå¤±è´¥: {e}")
        
        except Exception as e:
            print(f"âŒ åŸå§‹æ•°æ®åŠ è½½å¤±è´¥: {e}")
    
    else:
        print("â³ æš‚æ— æ–°çš„è®­ç»ƒç»“æœï¼Œè¯·ç­‰å¾…æ¨¡å‹è®­ç»ƒå®Œæˆ...")
        print("ğŸ’¡ å¯èƒ½çš„åŸå› :")
        print("  1. æ¨¡å‹è¿˜åœ¨è®­ç»ƒä¸­ï¼ˆTVAEé¢„è®¡5-8åˆ†é’Ÿï¼‰")
        print("  2. è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯")
        print("  3. è·¯å¾„é…ç½®é—®é¢˜")
    
    print("\n" + "=" * 60)
    print("ğŸ’¡ æç¤º: å¯ä»¥å®šæœŸè¿è¡Œæ­¤è„šæœ¬æ£€æŸ¥ä¼˜åŒ–æ•ˆæœ")
    print("ğŸ“ˆ å®Œæ•´åˆ†æè¯·è¿è¡Œ: python3 comprehensive_evaluator.py 169")

if __name__ == "__main__":
    analyze_optimization_results() 