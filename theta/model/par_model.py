#!/usr/bin/env python3
"""
åºåˆ—ä¸“ç”¨ PAR æ¨¡å‹ - åŸºäºæ¦‚ç‡è‡ªå›å½’çš„æ—¶é—´åºåˆ—ç”Ÿæˆæ¨¡å‹ ğŸ“ˆ
âœ¨ åºåˆ—å»ºæ¨¡: ä¸“é—¨é’ˆå¯¹æ—¶é—´åºåˆ—æ•°æ®è®¾è®¡ï¼Œå¤„ç†åºåˆ—ä¾èµ–å…³ç³»
é€‚ç”¨åœºæ™¯: æ—¶é—´åºåˆ—æ•°æ®ï¼Œå…·æœ‰æ˜ç¡®çš„æ—¶é—´é¡ºåºå’Œåºåˆ—ä¾èµ–å…³ç³»
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from sdv.sequential import PARSynthesizer
from sdv.metadata import SingleTableMetadata
from sdv.evaluation.single_table import evaluate_quality
from utils import *
import pandas as pd
import numpy as np

def main():
    print_model_info(
        "Sequential PAR", 
        "ğŸ“ˆ åºåˆ—ä¸“ç”¨æ¦‚ç‡è‡ªå›å½’æ¨¡å‹ï¼šæ—¶é—´åºåˆ—å»ºæ¨¡ + æ™ºèƒ½åºåˆ—å¤„ç† + åºåˆ—ä¾èµ–ä¼˜åŒ–"
    )
    
    # ğŸ“ˆ åºåˆ—æ¨¡å‹ä¸“ç”¨é…ç½®å‚æ•°
    data_path = "source_data/th_series_data.csv"
    output_dir = "output/par"
    sample_size = 12000  # ç»Ÿä¸€çš„é‡‡æ ·å¤§å°
    num_sequences = 50   # ç”Ÿæˆåºåˆ—æ•°é‡ï¼ˆPARä¸“ç”¨ï¼‰
    sequence_length = 40 # æ¯ä¸ªåºåˆ—é•¿åº¦
    epochs = 50          # PARè®­ç»ƒè½®æ•°
    target_user_id = 169 # ç›®æ ‡ç”¨æˆ·ID
    
    try:
        # 1. æ™ºèƒ½åºåˆ—æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
        print("\nğŸ”„ æ­¥éª¤1: æ™ºèƒ½åºåˆ—æ•°æ®å¤„ç†")
        
        # åŠ è½½æ•°æ®
        df = load_data(data_path)
        
        # åºåˆ—æ•°æ®é¢„å¤„ç†ï¼ˆå•ç”¨æˆ·æ•°æ®ï¼‰
        df_processed = preprocess_sequential_data(
            df, 
            user_col='user_id',
            target_user_id=target_user_id,
            sample_size=sample_size
        )
        
        if len(df_processed) == 0:
            raise ValueError("é¢„å¤„ç†åæ•°æ®ä¸ºç©º")
        
        print(f"ğŸ“Š âœ“ åºåˆ—é¢„å¤„ç†å®Œæˆï¼Œæœ€ç»ˆæ•°æ®: {df_processed.shape}")
        
        # 2. åˆ›å»ºåºåˆ—å…ƒæ•°æ®
        print("\nğŸ”„ æ­¥éª¤2: åˆ›å»ºåºåˆ—å…ƒæ•°æ®")
        metadata = create_sequential_metadata(df_processed)
        
        # 3. åˆå§‹åŒ–PARåˆæˆå™¨
        print("\nğŸ”„ æ­¥éª¤3: åˆå§‹åŒ–PARåˆæˆå™¨")
        synthesizer = PARSynthesizer(
            metadata=metadata,
            epochs=epochs,
            verbose=True
        )
        
        print(f"ğŸ“Š âœ“ PARåˆæˆå™¨åˆå§‹åŒ–å®Œæˆ (epochs={epochs})")
        
        # 4. å¸¦è¿›åº¦æ¡çš„æ¨¡å‹è®­ç»ƒ
        print("\nğŸ”„ æ­¥éª¤4: å¼€å§‹è®­ç»ƒ...")
        
        start_time = datetime.now()
        with progress_bar(total=epochs, desc="è®­ç»ƒPARæ¨¡å‹") as pbar:
            # PARçš„fitæ–¹æ³•æ²¡æœ‰callbackï¼Œæˆ‘ä»¬ä½¿ç”¨ç®€å•çš„è¿›åº¦æŒ‡ç¤º
            synthesizer.fit(df_processed)
            pbar.update(epochs)  # è®­ç»ƒå®Œæˆåæ›´æ–°è¿›åº¦æ¡
        
        train_time = datetime.now() - start_time
        print(f"ğŸ“Š âœ“ è®­ç»ƒå®Œæˆï¼è€—æ—¶: {train_time}")
        
        # 5. å¸¦è¿›åº¦æ¡çš„æ•°æ®ç”Ÿæˆ
        print(f"\nğŸ”„ æ­¥éª¤5: ç”Ÿæˆ {num_sequences} ä¸ªåºåˆ—...")
        
        with progress_bar(total=num_sequences, desc="ç”Ÿæˆåˆæˆæ•°æ®") as pbar:
            synthetic_data = synthesizer.sample(num_sequences=num_sequences)
            pbar.update(num_sequences)
        
        print(f"ğŸ“Š âœ“ æ•°æ®ç”Ÿæˆå®Œæˆï¼ç”Ÿæˆæ•°æ®: {synthetic_data.shape}")
        
        # 6. æ¨¡å‹è¯„ä¼°
        print("\nğŸ”„ æ­¥éª¤6: æ¨¡å‹è´¨é‡è¯„ä¼°")
        quality_report = evaluate_model(
            real_data=df_processed,
            synthetic_data=synthetic_data,
            metadata=metadata,
            model_name="Enhanced PAR"
        )
        
        # 7. ä¿å­˜ç»“æœå’ŒæŠ¥å‘Š
        print("\nğŸ”„ æ­¥éª¤7: ä¿å­˜ç»“æœ")
        summary_file = save_results(
            synthetic_data=synthetic_data,
            model_name="PAR",
            output_dir=output_dir,
            metadata=metadata,
            quality_report=quality_report,
            train_time=train_time
        )
        
        # 8. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        print("\nğŸ”„ æ­¥éª¤8: ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š")
        detailed_report_file = os.path.join(output_dir, "PAR_detailed_report.md")
        with open(detailed_report_file, 'w', encoding='utf-8') as f:
            f.write("# Enhanced PAR æ¨¡å‹è¯¦ç»†æŠ¥å‘Š\n\n")
            f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## ğŸ“Š åŸºæœ¬ä¿¡æ¯\n")
            f.write(f"- **æ¨¡å‹ç±»å‹**: Enhanced PAR (æ¦‚ç‡è‡ªå›å½’æ¨¡å‹)\n")
            f.write(f"- **ç›®æ ‡ç”¨æˆ·**: {target_user_id}\n") 
            f.write(f"- **è®­ç»ƒæ•°æ®**: {df_processed.shape[0]} è¡Œ Ã— {df_processed.shape[1]} åˆ—\n")
            f.write(f"- **ç”Ÿæˆæ•°æ®**: {synthetic_data.shape[0]} è¡Œ Ã— {synthetic_data.shape[1]} åˆ—\n")
            f.write(f"- **è®­ç»ƒæ—¶é—´**: {train_time}\n")
            f.write(f"- **è®­ç»ƒè½®æ•°**: {epochs}\n\n")
            
            if quality_report:
                overall_score = quality_report.get_score() * 100
                f.write("## ğŸ“ˆ è´¨é‡è¯„ä¼°\n")
                f.write(f"- **æ€»ä½“è´¨é‡åˆ†æ•°**: {overall_score:.2f}%\n")
                
                if overall_score >= 90:
                    quality_level = "ğŸ† å“è¶Š"
                elif overall_score >= 80:
                    quality_level = "ğŸ¥‡ ä¼˜ç§€"
                elif overall_score >= 70:
                    quality_level = "ğŸ¥ˆ è‰¯å¥½"
                elif overall_score >= 60:
                    quality_level = "ğŸ¥‰ ä¸€èˆ¬"
                else:
                    quality_level = "âš ï¸ éœ€è¦æ”¹è¿›"
                
                f.write(f"- **è´¨é‡ç­‰çº§**: {quality_level}\n\n")
            
            f.write("## ğŸ“‹ æ•°æ®ç»Ÿè®¡\n")
            f.write("### çœŸå®æ•°æ®ç»Ÿè®¡\n")
            f.write("```\n")
            f.write(df_processed.describe().to_string())
            f.write("\n```\n\n")
            
            f.write("### åˆæˆæ•°æ®ç»Ÿè®¡\n")
            f.write("```\n")
            f.write(synthetic_data.describe().to_string())
            f.write("\n```\n\n")
            
            f.write("## ğŸ” æ•°æ®æ ·ä¾‹\n")
            f.write("### çœŸå®æ•°æ®æ ·ä¾‹\n")
            f.write("```\n")
            f.write(df_processed.head(10).to_string())
            f.write("\n```\n\n")
            
            f.write("### åˆæˆæ•°æ®æ ·ä¾‹\n")
            f.write("```\n")
            f.write(synthetic_data.head(10).to_string())
            f.write("\n```\n")
        
        print(f"ğŸ“Š âœ“ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {detailed_report_file}")
        
        # 9. æœ€ç»ˆæ€»ç»“
        print("\n" + "="*60)
        print("ğŸ‰ Enhanced PAR æ¨¡å‹æ‰§è¡Œå®Œæˆ!")
        print("="*60)
        print(f"ğŸ“Š è®­ç»ƒæ•°æ®: {df_processed.shape}")
        print(f"ğŸ“Š ç”Ÿæˆæ•°æ®: {synthetic_data.shape}")
        print(f"â±ï¸  è®­ç»ƒè€—æ—¶: {train_time}")
        if quality_report:
            print(f"ğŸ“ˆ è´¨é‡åˆ†æ•°: {quality_report.get_score()*100:.2f}%")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
        print("="*60)
        
    except Exception as e:
        print(f"âŒ Enhanced PAR æ¨¡å‹æ‰§è¡Œå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True

if __name__ == "__main__":
    main() 